{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"8_텍스트이진분류(영어).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"dcJFEg-xd5Pt","colab_type":"text"},"source":["# 텍스트 이진분류 (영어 IMDB)"]},{"cell_type":"code","metadata":{"id":"Wze4leErbG92","colab_type":"code","colab":{}},"source":["# from google.colab import auth\n","# auth.authenticate_user()\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3dtyZ1iMeNwx","colab_type":"code","colab":{}},"source":["# 경로 설정\n","imdb_dir = '/content/gdrive/My Drive/pytest/aclImdb_v1_small/aclImdb/'\n","\n","!ls '/content/gdrive/My Drive/pytest/aclImdb_v1_small/aclImdb/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AMIXr6DhugF6","colab_type":"code","colab":{}},"source":["# Train Data Loading\n","import os\n","train_dir = os.path.join(imdb_dir, 'train')\n","labels = [] ; texts = []\n","\n","for label_type in ['neg', 'pos']:\n","  dir_name = os.path.join(train_dir, label_type)\n","  for fname in os.listdir(dir_name):\n","    if fname[-4:] == '.txt':\n","      f = open(os.path.join(dir_name, fname), encoding='utf8')\n","      texts.append(f.read())\n","      f.close()\n","      if label_type == 'neg':\n","        labels.append(0)\n","      else:\n","        labels.append(1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"csdswI_P1QPw","colab_type":"code","colab":{}},"source":["# Data 확인\n","print('texts 0:', texts[0])\n","print('texts len:', len(texts))\n","\n","print('labels 0:', labels[0])\n","print('labels len:', len(labels))\n","\n","print('texts type:', type(texts))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FOpgiSgK-Yvg","colab_type":"code","colab":{}},"source":["# texts = [['사과 감자 옥수수'], ['딸기 감자 옥수수'], ['양파 감자 옥수수'], ['양파 부추 옥수수']]\n","# texts = [['사과', '감자', '옥수수'], ['너희', '감자', '옥수수'], ['그들', '감자', '옥수수'], ['양파', '부추', '옥수수']]\n","# texts = ['사과 감자 옥수수 너희 그들 부추']\n","# texts = ['사과', '감자', '옥수수', '너희', '그들', '부추']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CnfO59ND2CF9","colab_type":"code","colab":{}},"source":["# Data Tokenizing\n","# 텍스트에 사용된 단어의 종류를 빈도 순으로 정렬하는 작업을 수행한다\n","%tensorflow_version 2.x\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np\n","import math\n","\n","validation_ratio = math.floor(len(texts) * 0.3)  \t# 검증 샘플은 전체의 30%로 한다\n","max_words = 10000               \t\t\t            # 데이터셋에서 가장 빈도 높은 10,000 개의 단어만 사용한다\n","maxlen = 200\t\t\t\t\t                            # 항상 200 단어가 되도록 길이를 고정한다\n","\n","tokenizer = Tokenizer(num_words=max_words)\t      # 상위빈도 10,000 개의 단어만을 추려내는 Tokenizer 객체 생성\n","tokenizer.fit_on_texts(texts)     \t\t\t          # 단어 인덱스를 구축한다 \n","word_index = tokenizer.word_index           \t\t  # 단어 인덱스만 가져온다 "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x9A8kRjB2o5B","colab_type":"code","colab":{}},"source":["# Tokenizing 결과 확인\n","print('전체에서 %s개의 고유한 토큰을 찾았습니다.' % len(word_index))\n","print('word_index type: ', type(word_index))\n","print('word_index: ', word_index)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m9a96D1i3dek","colab_type":"code","colab":{}},"source":["# Data Sequencing\n","# 문자를 숫자로 변환하는 작업을 수행한다\n","# 상위 빈도 10,000(max_words)개의 단어만 추출하여 word_index의 숫자 리스트로 변환한다.\n","data = tokenizer.texts_to_sequences(texts)\t\t# Tokenizer 결과가 여기서 반영된다.\n","\n","print('data 0:', data[0])\n","print('texts 0:', texts[0])\t\t\t\t           # texts[0]의 본래 단어들"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UQ8ye0wvtKE8","colab_type":"code","colab":{}},"source":["print(type(texts))\n","print(type(data))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oLVeU1OY4R3n","colab_type":"code","colab":{}},"source":["# Data Pading 연습\n","from keras.preprocessing.sequence import pad_sequences\n","\n","sequences = [[1, 2, 3, 4, 5], [1, 2, 3, 4], [1]]\t\t  # nested list\n","padded = pad_sequences(sequences, maxlen=3)\t\t  # 2D tensor \n","print(padded)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7UqhEqpi4BED","colab_type":"code","colab":{}},"source":["# Data Pading\n","data = pad_sequences(data, maxlen=maxlen) \n","\n","print('data:', data)\n","print('data 0:', data[0])\n","print(len(data[0]))\n","\n","print(word_index)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZedZvMhttOiG","colab_type":"code","colab":{}},"source":["print(type(texts))\n","print(type(data))\n","print(data.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uN3fTKON5lHA","colab_type":"code","colab":{}},"source":["# One-Hot-Encoding 연습\n","sample = [[5, 6, 7], [8, 9, 10]]\n","arr = np.zeros((len(sample), 10+1))\t\t# “10”은 11번째에 들어가게 되므로 11개의 공간을 만들어야 한다\n","for i, seq in enumerate(sample):\t\t  # 리스트가 2개이므로 i는 총 2회(0, 1) 반복되며,\n","   \tarr[i, seq] = 1.\t\t\t\t          # 각 i에서 리스트의 number가 가리키는 곳에 1을 기록한다\n","arr"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AKoQ8Px26eRG","colab_type":"code","colab":{}},"source":["# One-Hot-Encoding\n","def to_one_hot(sequences, dimension):\n","  results = np.zeros((len(sequences), dimension))\n","  for i, sequence in enumerate(sequences):\n","    results[i, sequence] = 1.\n","  return results\n","\n","\n","data = to_one_hot(data, dimension=max_words) \n","labels = np.asarray(labels).astype('float32')   "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8aws96UB77l8","colab_type":"code","colab":{}},"source":["# One-Hot-Encoding 결과 확인\n","\n","print('data:', data)\n","print(len(data[0]))\t\t\t\t\t# dimension=10000으로 했으므로 각 행은 10,000개를 가지고 있다\n","print('data [0][0:100]:', data[0][0:100])\n","\n","print(word_index)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"saK62RogwkR0","colab_type":"code","colab":{}},"source":["print(type(texts))\n","print(type(data))\n","print(data.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iJAVEnUo9URz","colab_type":"code","colab":{}},"source":["# Train 데이터와 Validation 데이터 준비\n","\n","print('데이터 텐서의 크기:', data.shape)  \t\t# (25000, 10000)\n","print('레이블 텐서의 크기:', labels.shape) \t\t# (25000,) data와 label이 모두 2D 텐서가 되었음\n","\n","indices = np.arange(data.shape[0]) \t\t        # 0 ~ 24999 까지의 숫자를 생성\n","np.random.shuffle(indices)     \t\t\t          # 0 ~ 24999 까지의 숫자를 랜덤하게 섞음\n","data = data[indices]    \t\t\t\t              # 이것을 인덱스로 하여 2D 텐서 데이터를 섞음 \n","labels = labels[indices]\t\t\t\t              # label도 같은 순서로 섞음 \n","\n","print(indices)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4yd1MRmY-iS5","colab_type":"code","colab":{}},"source":["# 훈련데이터와 검증데이터 분리\n","x_train = data[validation_ratio:] \t\t\t      # 훈련데이터의 70%를 훈련데이터\n","y_train = labels[validation_ratio:] \t\t\t    # 훈련데이터의 70%를 훈련데이터 Label (data와 labels는 같은 순서)\n","x_val = data[:validation_ratio] \t\t\t        # 훈련데이터의 30%를 검증데이터\n","y_val = labels[:validation_ratio] \t\t\t      # 훈련데이터의 30%를 검증데이터 Label"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c4QucBVc_Oti","colab_type":"code","colab":{}},"source":["# 모델 정의하기\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","model = Sequential()                                              # 모델을 새로 정의\n","\n","model.add(Dense(64, activation='relu', input_shape=(max_words,)))\t# 첫 번째 은닉층\n","model.add(Dense(32, activation='relu'))                           # 두 번째 은닉층\n","model.add(Dense(1, activation='sigmoid'))                 \t\t    # 출력층"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wZ2WIgYgALdz","colab_type":"code","colab":{}},"source":["# 모델 요약 출력\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xvoxvHYdHnlu","colab_type":"code","colab":{}},"source":["# Compile & Train Model\n","# 모델 컴파일\n","# 가중치 업데이트 방법은 RMSprop을 사용하였다. 이동평균의 방법을 도입하여 조절해간다\n","# 신경망의 출력이 확률이므로 crossentropy를 사용하는 것이 최선이다\n","# crossentropy는 원본의 확률 분포와 예측의 확률 분포를 측정하여 조절해 간다\n","# 또한 이진 분류이므로 binary_crossentropy를 사용한다\n","model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n","\n","# 모델 훈련\n","# 32개씩 미니 배치를 만들어 10번의 epoch로 훈련한다. 보통 32개에서 시작하여 512개까지 중에서 찾는다\n","# 훈련 데이터로 훈련하고, 검증 데이터로 검증한다 \n","# 반환값의 history는 훈련하는 동안 발생한 모든 정보를 담고 있는 딕셔너리이다\n","history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))\n","history_dict = history.history"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OW3LNuktJNSd","colab_type":"code","colab":{}},"source":["# 경로 변경\n","cd /content/gdrive/My Drive/pytest/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ff9MJD0qJv-M","colab_type":"code","colab":{}},"source":["# Save Model\n","# multidimensional numpy arrays를 저장할 수 있는 h5 file(HDF) 포맷으로 저장한다\n","model.save('text_binary_model.h5')\n","\n","\n","# 훈련데이터에서 사용된 상위빈도 10,000개의 단어로 된 Tokenizer 저장\n","# 새로 입력되는 문장에서도 같은 단어가 추출되게 한다\n","import pickle\n","with open('text_binary_tokenizer.pickle', 'wb') as handle:\n","  pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KX6DFPtVLBkm","colab_type":"code","colab":{}},"source":["# Accuracy & Loss 확인\n","# history 딕셔너리 안에 있는 정확도와 손실값을 가져와 본다\n","\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","print('Accuracy of each epoch:', acc)\t\t# [0.79, 0.90, 0.93, 0.94, 0.96, 0.97, 0.98, 0.98, 0.98, 0.99]\n","epochs = range(1, len(acc) +1)\t\t\t# range(1, 11)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"46S6mH6yLRKE","colab_type":"code","colab":{}},"source":["# Plotting Accuracy\n","import matplotlib.pyplot as plt\n","\n","# 훈련데이터의 정확도에 비해 검증데이터의 정확도는 낮게 나타난다\n","# epoch가 높아지면 모델은 훈련데이터에 매우 민감해져 오히려 새로운 데이터를 잘 못 맞춘다\n","plt.plot(epochs, acc, 'bo', label='Training Acc')\n","plt.plot(epochs, val_acc, 'b', label='Validation Acc')\n","plt.title('Training and validation accuracy')\n","plt.legend()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x92OIlNBLlr7","colab_type":"code","colab":{}},"source":["# Plotting Loss\n","plt.figure()    # 새로운 그림을 그린다\n","\n","# 훈련데이터의 손실값은 낮아지나, 검증데이터의 손실값은 높아진다\n","# 손실값은 오류값을 말한다. 예측과 정답의 차이를 거리 계산으로 구한 값이다\n","plt.plot(epochs, loss, 'bo', label='Training Loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YdSjF0UoL-zX","colab_type":"code","colab":{}},"source":["# Load Model\n","import os\n","from tensorflow.keras.models import load_model\n","\n","filepath = '/content/gdrive/My Drive/pytest/'\n","os.chdir(filepath)\n","print(\"Current Directory:\", os.getcwd())\n","\n","loaded_model = load_model('text_binary_model.h5')\n","print(\"model loaded:\", loaded_model)\n","\n","with open('text_binary_tokenizer.pickle', 'rb') as handle:\n","  loaded_tokenizer = pickle.load(handle)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BkREhL_RNgei","colab_type":"code","colab":{}},"source":["# Test Data Loading\n","test_dir = os.path.join(imdb_dir, 'test')\n","labels = [] ; texts = []\n","\n","for label_type in ['neg', 'pos']:\n","  dir_name = os.path.join(test_dir, label_type)\n","  for fname in os.listdir(dir_name):\n","    if fname[-4:] == '.txt':\n","      f = open(os.path.join(dir_name, fname), encoding='utf8')\n","      texts.append(f.read())\n","      f.close()\n","      if label_type == 'neg':\n","        labels.append(0)\n","      else:\n","        labels.append(1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BR-PxsNkN-PI","colab_type":"code","colab":{}},"source":["# Data 확인\n","print('texts:', texts[0])\n","print('texts len:', len(texts))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jmmu_JkSODJH","colab_type":"code","colab":{}},"source":["# Data Sequencing\n","# 문자열을 word_index의 숫자 리스트로 변환\n","data = loaded_tokenizer.texts_to_sequences(texts)\n","\n","# padding으로 문자열의 길이를 고정시킨다\n","data = pad_sequences(data, maxlen=maxlen) \n","\n","# test 데이터를 원-핫 인코딩한다\n","x_test = to_one_hot(data, dimension=max_words)\n","\n","# label을 list에서 넘파이 배열로 변환. 결과가 0 또는 1만 나오므로 이와같이 int32로 저장해도 된다.\n","y_test = np.asarray(labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gEEE6VIKOPJC","colab_type":"code","colab":{}},"source":["# Test Data Evaluation\n","test_eval = loaded_model.evaluate(x_test, y_test)\t  # 모델에 분류할 데이터와 그 정답을 같이 넣어준다\n","print('prediction model loss & acc:', test_eval)\t\t# 모델이 분류한 결과와 입력된 정답을 비교한 결과"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xnvfHT1GOYwd","colab_type":"code","colab":{}},"source":["# 1개 데이터 예측\n","text = [\"Hi, this is a test sentence.\"]      # 데이터를 list 타입으로 만든다\n","data = loaded_tokenizer.texts_to_sequences(text)\n","data = pad_sequences(data, maxlen=maxlen)\n","x_test = to_one_hot(data, dimension=max_words)\n","\n","prediction = loaded_model.predict(x_test)\n","print(\"Result:\", prediction)\t\t\t\t\t       # [[0.53135556]]. 1이 될 확률이 53.1%"],"execution_count":0,"outputs":[]}]}